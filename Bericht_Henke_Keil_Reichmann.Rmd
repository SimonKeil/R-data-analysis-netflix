---
title: "R-Projekt"
author: "Márk Reichmann, Simon Keil, Daniel Henke"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
	fig.show = "hold",
	message = FALSE,
	warning = FALSE,
	echo = FALSE
)
```

## Einleitung

Als 1997 ein kleine Online-Videothek für DVDs in Kalifornien gegründet wurde, war niemanden klar, wie dieses Unternehmen die Welt verändern würde. Jetzt, knapp 25 Jahre später, ist Netflix der größte Video-on-Demand-Anbieter der Welt mit knapp 200 Millionen Abonnenten [1]. Der Streaming-Riese ist heute in mehr als 190 Ländern verfügbar und hat tausende Inhalte in verschieden Sprachen [2].

Hierbei hat Netflix eine große Bandbreite an Filmen und Serien in verschiedensten Genres und aus verschiedenen Jahren. Netflix kauft und produziert Inhalte oft basierend auf intensiven Datenanalysen, sodass ihr Sortiment keiner wahllosen Zusammenstellung sondern eher einer kuratierten Auswahl gleicht [3].

Dadurch ist die Auswahl, welche Inhalte auf Netflix verfügbar sind und wie diese im Zusammenhang mit Genre, Erscheinungsjahr und weiteren Charakteristika zusammengestellt sind sehr spannend und weit mehr als nur ein Querschnitt aller produzierten Inhalte. Insbesondere erweist sich der Vergleich von älteren und neueren Inhalten als interessant. Deshalb wollen wir in diesem Bericht der Frage nachgehen: _Wie verhalten sich die Inhalte auf Netflix bezüglich ihres Erscheinungsjahres?_

Hierzu benutzen wir einen Datensatz von Kaggle, den Ashish Gupta zusammen- und zur Verfügung gestellt hat und der unter [4] abzurufen ist. Da es keine offizielle Netflix-API gibt, wurden hier Daten von mehreren verschiedenen APIs und Seiten wie "Rotten Tomatoes", "iMDB" und weiteren Quellen zusammengetragen. Zudem hat er eine eigene Metrik, den "Hidden Gem Score", hinzugefügt, der aus den Daten Geheimtipps ermitteln soll. Diesen haben wir aber für unsere Betrachtungen nicht beachtet, da es sich lediglich um einen aus den anderen Variablen erzeugten Wert handelt.

Im Datensatz finden sich 29 Variablen pro Inhalt, die vom Titel über verschiedene Genre-Variablen bis hin zu Regisseur und Schauspieler reichen. Ebenfalls verfügbar sind die verfügbaren Sprachen, verschiedene Bewertungsmetriken (von IMDb, Rotten Tomatoes, Metacritic) und weitere Kenngrößen, mit denen wir uns nicht weiter befasst haben. Im Folgenden haben wir vor allem das Veröffentlichungsjahr, die Genres und die Länderverfügbarkeit sowie ihre Zusammenhänge untersucht.

Da die Daten aus unterschiedlichen Quellen kommen und somit sehr heterogen sind, sind manche Variablen vertrauenswürdiger als andere. Teilweise tauchen Filme und Serien mehrmals auf, um diese Duplikate müssen wir uns speziell kümmern. Zum Teil scheinen die Sprachen nicht vollständig richtig zu sein, da zum Beispiel auch "Latin" als Sprache genannt wird, was wir durch manuelles Abgleichen mit Netflix nicht bestätigen konnten. Wir vermuten Übersetzungsfehler, können aber den Fehlerursprung nicht eindeutig ermitteln. Manchmal sind auch beim Zusammenfügen der Daten aus verschiedenen Quellen Fehler aufgetreten. So ist vermutlich bei der Serie "Barbarians" die Netflix-Serie deutscher Herkunft mit dem iMDB-Eintrag des tschechischen Films "Barbarians" (im Original "Varvari") aus 2014 verbunden worden. Die Daten sind zum Teil von der Serie, zum Teil vom Film.

Da dies aber (nach unserem Wissen) Einzelfälle sind und es zu diesem Thema kaum bis keine besseren Daten gibt, haben wir trotz dieser Probleme dieses Datenset verwendet. Um den Imperfektionen des Datensatzes zusätzlich aus dem Weg zu gehen, haben wir uns zudem auf Spalten konzentriert, die sehr vollständig sind und in denen uns keine offensichtlichen Inkonsistenzen aufgefallen sind.

## Explorative Datenanalyse

*Anmerkung zu Beginn der Analyse:* Wir lesen vor der eigentlichen Auswertung die Daten ein und reduzieren sie auf den Grund-Datenbestand, den wir im Folgenden nutzen wollen: Die Spalten mit dem Titel, Genres, Veröffentlichungsdatum und Länder Verfügbarkeit. Dabei enfernen wir zudem alle Zeilen in denen Angaben fehlen sowie die Inhalte mit Veröffentlichungsdatum vor 1965 und nach 2020, da in diesen Jahren nur sehr wenige Einträge vorhanden sind, sodass keine sinnvollen Aussagen getroffen werden können. Zudem entfernen wir, wie oben angesprochen, Duplikate, indem wir Einträge mit gleichem Titel und Veröffentlichungsjahr zu einem Eintrag zusammenfassen.


```{r}
library("tidyverse")
raw_data <- read_csv("Data/netflix-rotten-tomatoes-metacritic-imdb.csv")

data <- raw_data %>%
  rename(country = 'Country Availability') %>%
  # reformat release date to only the year
  mutate(year = as.integer(substr(`Release Date`, 8, 12))) %>% 
  # exclude years with close to no entries
  filter(year > 1965 & year < 2020) %>% 
  select(Genre, year, Title, country) %>%
  drop_na()

# unique content + Genre
content_genre <- data %>%
  select(Genre, year, Title) %>% 
  separate_rows(Genre, sep = ", ") %>%
  distinct(.keep_all = TRUE)

# unique content + country
content_country <- data %>%
  select(year, Title, country) %>% 
  separate_rows(country, sep = ",") %>%
  distinct(.keep_all = TRUE)

# dataset with list of genres and countries separated into individual rows
data_expanded <- full_join(content_genre, content_country, by = c("year", "Title")) %>%
  ungroup()

# dataset with list of genres separated into individual rows
data_genre <- data_expanded %>%
  group_by(Genre, year, Title) %>%
  summarise(country = paste(country, collapse = ", ")) %>%
  ungroup()

# dataset with list of countries separated into individual rows
data_country <- data_expanded %>%
  group_by(country, year, Title) %>%
  summarise(Genre = paste(Genre, collapse = ", ")) %>%
  ungroup()

# dataset to work with throughout the analysis
data_basic <- data_genre %>%
  group_by(country, year, Title) %>%
  summarise(Genre = paste(Genre, collapse = ", ")) %>%
  ungroup()
```

Zunächst schauen wir uns ein paar allgemeine Zahlen zu unserem (aufgeräumten) Datensatz an. Wir beginnen mit einer statistischen Übersicht zu den Veröffentlichungsjahren:
```{r}
summary(data_basic$year)
```
Wir beobachten zum einen, dass nur noch Werte von 1961 bis 2019 im Datensatz sind (wie oben begründet) und zum anderen, dass sehr viele Inhalte aus den letzten Jahren stammen, allein 25% aus den Jahren 2017 bis 2019.
Diese Beobachtung sieht man auch, wenn man die Zahl der Inhalte in dem jeweiligen Veröffentlichungsjahr darstellt. Im Plot zeichnet sich sogar ab, dass die Zahl der Inhalte annährend exponentiell mit jüngerem Veröffentlichungsdatum steigt, weshalb die Anzahl im Plot mit einer logarithmischen Skala versehen ist.

```{r}
data_basic %>% 
  count(year) %>% 
  ggplot(aes(x = year, y = n)) +
  geom_point() +
  scale_y_log10() +
  labs(x = "Veröffentlichungsjahr",
    y = "Anzahl der Inhalte")
```

```{r, include=FALSE}
(data_country %>% distinct(country) %>% count())$n
```
Nun schauen wir uns die Länder in unserem Datensatz etwas genauer an. Es gibt 36 Länder in unserem Datensatz. Eine interessante Kenngröße, die wir für diese Länder betrachten können ist, wieviele Filme und Serien es jeweils in den Ländern gibt.

```{r}
data_country %>%
  count(country)%>%
  select(n, country)%>%
  ggplot(aes(x = n, y = reorder(country, n)))+
  geom_point()+
  labs(title = "Anzahl verfügbarer Inhalte in den Ländern",
       x = "Anzahl der Inhalte", 
       y = "Land")
```

Man sieht, dass es starke Unterschiede zwischen den einzelnen Ländern gibt und dass keine Gruppenbildung in z.B. Länder mit sehr viel und Ländern mit weniger Inhalten zu erkennen ist. Eine naheliegende nächste Frage ist, wie sich die verschiedenen Anzahlen zusammensetzen, also ob sehr viele Inhalte in vielen Ländern verfügbar sind und im oberen Plot bei benachbarten Ländern sich das Angebot nur minimal unterscheidet, oder ob sich die Anzahl zwar wenig unterscheidet aber die tatsächlichen Inhalte stark.
Betrachten wir die Anzahl der Länder in denen einzelne Inhalte verfügbar sind, wird deutlich, dass letzteres der Fall ist.

```{r}
data_country %>% 
  count(Title, year) %>%
  ggplot(mapping = aes(x = n)) +
  geom_histogram(boundary = 0, bins = 36) +
  labs(title = "Internationale Verfügbarkeit von Inhalten",
       x = "Anzahl Länder",
       y = "Anzahl Inhalte")
```

Tatsächlich ist ein Großteil der Medien nur in einem einzigen Land abrufbar, das Angebot von Netflix scheint also recht speziell auf einzelne Länder zugeschnitten zu sein. Nur ganz rechts im Plot sehen wir eine zweite Häufung mit rund 1500 sehr international verfügbaren Inhalten.

Im Bezug auf unsere Forschungsfrage besonders spannend ist die Frage, ob diese sehr internationalen Inhalte möglicherweise die neueren Inhalte auf Netflix sind. Wir betrachten also die Internationalität in Bezug auf das Veröffentlichungsdatum.

```{r}
data_country %>% 
  count(Title, year) %>%
  group_by(year) %>% 
  summarise(number = mean(n)) %>%
  ggplot(aes(x = year, y = number)) +
  geom_point() +
  labs(title = "Internationalität im zeitlichen Verlauf",
       y = "Durchschnittliche Zahl der Länder pro Inhalt",
       x = "Veröffentlichungsjahr") +
  geom_smooth()
```

Hier sehen wir eine interessante Korrelation, die auf eine stärkere Internationalität hinweist, je neuer der Inhalt ist. Dieser Effekt wird auch durch die geplottete Glättungskurve deutlich. (Diese wird mit einer lokalen polynomiellen Regression (loess, siehe Dokumentation des stats-package) erzeugt, worauf wir aber hier nicht näher eingehen wollen.)

```{r, include=FALSE}
(data_genre %>% distinct(Genre) %>% count())$n
```

Zuletzt untersuchen wir noch die Genres. Dafür betrachten wir zuerst die Anzahl der Inhalte die in dem jeweiligen der 27 Genres verfügbar sind.

```{r}
data_genre %>%
  count(Genre) %>% 
  arrange(n) %>%
  ggplot(aes(x = factor(Genre, levels = Genre), y = n)) +
  geom_bar(stat = 'identity') +
  labs(title = "Ranking der Genres",
    x = "Genre",
    y = "Anzahl der Inhalte") +  coord_flip()
```

Wir beobeachten, dass Drama und Comedy die mit Abstand am weitesten verbeiteten Genres sind, und das nur die Hälfte der Genres überhaupt über 1000 zugeordnete Inhalte haben. Das bedeutet, dass es ein paar wenige Genres denen sehr viele Inhalte zugeordnet sind gibt und gleichzeitig eine große Breite an spezifischeren Genres mit weniger Inhalten.

Um dieses Ranking der Genres nicht nur allgemein sondern abhängig vom Veröffentlichungsjahr zu visualisieren, schauen wir uns den Anteil der jeweiligen Genres an, den diese an allen Inhalten aus einem spezifischen Veröffentlichungsjahr haben. Wir bekommen folgendes interessantes Bild:

```{r}
year_per_genre <- data_genre %>%
  count(year, Genre)
year_genre_total <- data_genre %>% count(year)
left_join(year_per_genre, year_genre_total, by = "year") %>% 
  mutate(prop = n.x/n.y) %>% 
  ggplot(aes(x = year, y = prop, color = Genre)) +
  geom_point(size = 1) +
  labs(title = "Anzahl der verfügbaren Genres nach Veröffentlichungsjahr",
    x = "Veröffentlichungsjahr",
    y = "Anteil der Genres")
```

Zum einen stechen erneut die beiden "Überflieger" Drama und Comedy ins Auge, die, mit wenigen Ausnahmen bei älteren Jahren, die beiden größten Anteile stellen. Des Weiteren fällt im unteren rechten Bereich das Auftreten von overplotting unangenehm auf. Doch trotz (bzw. sogar wegen) des overplotting ist erkennbar, dass es mit zunehmender Jahreszahl mehr Genres gibt und dass die einzelnen Genres dazu tendieren einen kleineren Anteil auszumachen, denn der Bereich unten rechts sind genau die jüngsten Jahre und die geringen Anteile.
Wir visualisieren also die Daten auf eine neue Art und Weise, um den Effekt deutlicher und ohne overplotting herauszuarbeiten. Eine Möglichkeit wäre den durchschnittlichen Anteil gemittelt über alle Genres pro Jahr darzustellen. Wir wählen aber die reziproke Darstellung des selben Zusammenhangs, das heißt wir betrachten die Anzahl der Genres pro Veröffentlichungsjahr, in denen Inhalte verfügbar sind.

```{r}
count_genre_vs_year <- data_genre %>%
  select(Genre, year) %>% 
  group_by(year) %>% 
  distinct() %>% 
  count(year)
count_genre_vs_year %>%
  ggplot(aes(x = year, y = n)) +
  geom_point() +
  labs(title = "Anzahl der Genres nach Veröffentlichungsjahr",
       x = "Veröffentlichungsjahr",
       y = "Anzahl der Genres")
```

Wir sehen einen annähernd linearen Zusammenhang, den wir im Folgenden näher untersuchen wollen. Davor wollen wir aber noch ausschließen, dass der Zusammenhang, den wir sehen, durch die Art unseres Datensatzes induziert wird und keinen echten Zusammenhang abbildet, denn in unserem Datensatz wird ein Film oder eine Serie in der Regel mehreren Genres zugeordnet. Es könnte also sein, dass neuere Inhalte einfach mehr unterschiedlichen Genres zugeordnet werden. Um das zu untersuchen, plotten wir die durchschnittliche Zahl der Genres denen ein Film oder eine Serie in einem gegebenen Jahr zugeordnet wird:

```{r}
data_genre %>%
  count(Title, year) %>%
  group_by(year) %>% 
  summarise(number = mean(n)) %>% 
  ggplot(aes(x = year, y = number)) +
  geom_point() +
  labs(title = "Anzahl der Genres pro Inhalt im zeitlichen Verlauf",
       y = "Durchschnittliche Zahl der Genres pro Inhalt",
       x = "Veröffentlichungsjahr")
```

Anhand des Plots lässt sich diese Vermutung widerlegen, denn die Zahl der Genres bewegt sich fast immer zwischen 2.5 und 3, mit wenigen Ausreißern. Bei den Inhalten der letzten Jahre ist sogar eher ein Abwärtstrend erkennbar, im Gegensatz zu dem Aufwärtstrend der Zahl der Genres.
 
## Methoden

Den annähernd linearen Zusammenhang, auf den wir in der explorativen Analyse gestoßen sind, wollen wir genauer untersuchen. Hierfür gibt es die statistische Methode der linearen Regression. Grundlage dafür ist das lineare Regressionsmodell
$$
Y_i = \beta x_i + \alpha + \varepsilon_i \text{ für } 1 \leq i \leq n
$$
mit $n \in \mathbb{N}$ die Anzahl der Messwerte zu den Eingabestellen $x_i$, in unserem Fall die Jahreszahlen, und den beobachteten Zufallsvariablen $Y_i$, in unserem Fall die Anzahl der Genres, sowie den Fehlertermen $\varepsilon_i$ die normalverteilt sind mit Erwartungswert $0$ und unbekannter, endlicher Varianz.

Um aus den Messwerten und den Beobachtungen der $Y_i$ die Koeffizienten $\alpha$ und $\beta$ des linearen Modells zu berechnen, kann man die Methode der kleinsten Quadrate benutzen, die die Summe der quadratischen Abweichungen minimiert. Für den theoretischen Zusammenhang der Koeffizienten mit empirischen Größen siehe [5], für eine in der Regel numerisch stabile Berechnung der Koeffizienten siehe [6].

Da die tatsächliche Verteilung der Fehlerterme unbekannt ist, ist es sinnvoll die konkreten Fehlerterme auf Normalverteilung mit Erwartungswert $0$ hin zu untersuchen. Das bedeutet für gegebene Messwerte $y_i$ und $\alpha$, $\beta$ berechnet durch die Methode der kleinsten Quadrate, betrachten wir die Residuen $r_i = y_i - \beta x_i - \alpha$ und wollen überprüfen, ob diese als Realisierung einer $N(0,\sigma^2)$ verteilten Zufallsvariable plausibel sind. Hierfür gibt es den Shapiro-Wilk-Test, der auf Normalverteilung testet [7]. Er hat als Ausgabe eine Statistik $W$, die für unsere Zwecke aufgrund einer zu großen Stichprobe wenig interessant ist, und einen $p$-Wert, der angibt mit welcher Wahrscheinlichkeit man eine Stichprobe wie $e_i$ erhält, unter der Annahme einer Normalverteilung. Liegt der p-Wert nahe der Eins, kann man von einer Normalverteilung ausgehen. Als Schätzer für den Erwartungswert kann man das empirische Mittel verwenden, liegt dieses zusätzlich nahe der 0, kann man von der gewünschten $N(0,\sigma^2)$-Verteilung ausgehen. Als zusätzliches visuelles Kriterium für eine Normalverteilung kann außerdem ein Normal-Quantil-Plot angelegt werden.

Hat man nun die Normalverteilung der Residuen festgestellt und so die Anwendung der linearen Regression gerechtfertigt, kann man nun die Güte der linearen Regression beurteilen. Eine Größe, die hierfür relevant ist, ist das Bestimmtheitsmaß $R^2$, das angibt, wie gut das Modell die Beobachtungen approximiert. Präziser: Welcher Teil der Varianz der beobachteten Werte durch das Modell erklärt werden kann, und welcher nicht erklärt werden kann, also von den $\varepsilon_i$ stammt. Ein Wert nahe der Eins spricht für eine gute Anpassung, ein Wert nahe der Null für eine schlechte.

Zudem kann man zu den beiden Koeffizienten $\alpha$ und $\beta$ jeweils einen $p$-Wert bestimmen, der angibt, wie wahrscheinlich es ist die Beobachtung die gemacht wurde zu machen, unter der Annahme, dass kein Einfluss des Koeffizienten bestünde, also das dieser 0 sei. Ist der $p$-Wert klein kann man von einem Zusammenhang ausgehen. Analog funktioniert der $F$-Statistik, die sich allerdings auf alle Koeffizienten simultan bezieht. [8]

## Ergebnisse und Schlussfolgerungen

Die oben beschriebenen Methoden wollen wir nun auf den beobachteten Zusammenhang zwischen Veröffentlichungsjahr unf Anzahl der Genres anwenden. Zunächst erstellen wir ein lineares Modell für die beiden Variablen:

```{r}
count_genre_vs_year %>%
  ggplot(aes(x = year, y = n)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Anzahl der Genres nach Veröffentlichungsjahr",
       x = "Veröffentlichungsjahr",
       y = "Anzahl der Genres")
lm <- lm(count_genre_vs_year$n ~ count_genre_vs_year$year)
```

Darauf basierend untersuchen wir nun die Residuen, wie zuvor beschrieben. Den ersten Schritt bildet ein Normal-Quantil-Plot der Residuen:

```{r}
residuals <- count_genre_vs_year %>%
  mutate(residual = n - coef(lm)[1] - year * coef(lm)[2])
residuals %>% 
  ggplot(aes(sample = residual)) +
  stat_qq() +
  stat_qq_line() + 
  labs(title = "Normal-Quantil-Plot der Residuen")
```

Wir beobachten zwei Dinge: Erstens, alle Punkte liegen nahe der Geraden einer perfekten Normalverteilung, die Residuen sind also annährend normalverteilt. Und zweitens, der Erwartungswert liegt vermutlich nahe der 0, da die Punkte in etwa symmetrisch um (0,0) liegen. Diese visuelle Untersuchung würde also für eine $N(0,\sigma^2)$ Verteilung sprechen, wie gewünscht. Wir wollen nun diese Vermutung mit dem Shapiro-Wilk-Test weiter untermauern:

```{r}
shapiro.test(residuals$residual)
```

Der $p$-Wert von $0.84$ ist relativ hoch. Der Test legt also eine Normalverteilung nahe. Betrachten wir nun noch das empirische Mittel der Residuen als Approximation des Erwartungswert erhalten wir
```{r}
mean(residuals$residual)
```

einen Wert der extrem nahe an der 0 liegt. Wir können also sinnvollerweise von einer $N(0,\sigma^2)$ der Residuen ausgehen. So haben wir nun die Anwendbarkeit der linearen Regression gezeigt. Wir gehen nun zur Beurteilung über. Dafür schauen wir uns eine Übersicht über das erstellte lineare Modell an:

```{r}
summary(lm)
```

Neben der Übersicht über die Residuen, die wir bereits untersucht haben sind besonders die Informationen zu den Koeffizienten interessant. Die $p$-Werte der beiden Koeffizienten und der $F$-Statistik lassen alle mit sehr großer Sicherheit den Schluss zu, dass ein Einfluss der Koeffizienten besteht. Der $R^2$ Wert von $0.90$ ist nahe der Eins und damit ebenfalls ein gutes Indiz für ein sinnvolles Modell. Zusammenfassend lässt sich sagen, dass alle Größen deutlich die Vermutung eines linearen Zusammenhangs stützen, oder zumindest diesem nicht widersprechen.

Wir sehen uns nun die numerischen Werte der Koeffizienten an. Das Lineare Modell beschreibt den Zusammenhang
$$
\text{Anzahl der Genres} = \text{Jahreszahl} \cdot 0.265 - 508.858
$$
In dieser Form ist die Formel aber wenig sinnvoll, insbesondere der konstante Term $-508$, da eine Betrachtung im Jahr 0 natürlich Unfug ist. Wir schreiben die Formel also besser relativ zum Beginn unserer Daten, also 1965. Das führt auf

```{r, include = FALSE}
coef(lm)[1] + 1965 * coef(lm)[2]
```

$$
\text{Anzahl der Genres} = 0.265 \cdot (\text{Jahreszahl} - 1965) + 12.445.
$$

In dieser Form ist offensichtlich, dass das lineare Modell einen durchschnittlichen Zuwachs von einem verfügbaren Genre rund alle 4 Jahre vorhersagt, ausgehend von gut 12 Genres im Jahr 1965. Aufgrund der vorhergehenden Überlegungen kann vernünftigerweise davon ausgegeangen werden, dass der tatsächliche Zusammenhang durch diese Formel sehr gut approximiert wird.

**Fazit des Projekts und Bezug auf Forschungsfrage**

Woran liegt diese lineare Steigung der Genre-Anzahl? Wir sehen hier zwei plausible Einflussfaktoren: die Auswahl von Netflix und eine allgemeine Genre-Zunahme in der Film- & TV-Industrie.

Netflix wählt nämlich, wie in der Einleitung schon festgestellt, die zur Verfügung gestellten Inhalte sehr genau und auch datenbasiert aus [3]. Aufgrund von Konkurrenz im Streaming-Bereich hat Netflix in den letzten Jahren mehr und mehr eigene Inhalte für ihre Plattform erstellt (diese werden innerhalb unserer Daten leider bei Serien nicht als solche in "Production House" deklariert, sodass dies nach unseren Daten nicht genauer nachvollziehbar sind). Seit den ersten Netflix-Original Inhalten in 2012/13 ist die Anzahl kontinuierlich gestiegen. So hat z.B. 2019 Netflix 657 Originialinhalte auf ihrer Plattform gestellt [9]. Bei diesen Inhalten hat Netflix komplette kreative Kontrolle, sodass sie in den letzten Jahren diverse Inhalte in diversen Genres erstellen konnten.

Da dies aber höchstens den Anstieg ab 2012/13 erklären würde (und dieser nicht erkennbar höher als die Jahre zuvor), ist dieser Anstieg vermutlich eher mit einem allgemeinen Anstieg an Genre-Diversität in der Film- und TV-Industrie. _(Ich hätte hier gerne eine Quelle, die das gleiche oder das gegenteilige behauptet, ich hab leider nichts gefunden. Gerne ergänzen, falls ihr da was habt. ~Daniel)_ Da unsere Daten aber nur eine Teilmenge aller Filme und Serien darstellt, können wir einen allgemeinen Trend nicht definitiv nachweisen. 

Dennoch bleibt es spannend zu beobachten, inwiefern dieser Trend bestehen bleibt. Wird es in den nächsten Jahren noch weiter linear wachsend mehr Genres geben oder erreichen wir in Zukunft einen Hoch- und Wendepunkt? Nur die Zeit wird zeigen, wie Genre-divers die Inhalte sein werden - auf dieser ehemals kleinen Online-Videothek aus Kalifornien.


## Literatur
[1] Statista Research Department (2021). _Netflix: Daten und Fakten zur Erfolgsgeschichte des Streaming-Riesen_. https://de.statista.com/themen/1840/netflix/

[2] Netflix. _Where ist Netflix available?._ https://help.netflix.com/en/node/14164

[3] Netflix. _How does Netflix license TV shows and movies?._ https://help.netflix.com/en/node/4976#:~:text=Netflix%20uses%20a%20variety%20of,shows%20and%20movies%20we%20suggest.

[4] Gupta, A. _Daten._ https://www.kaggle.com/ashishgup/netflix-rotten-tomatoes-metacritic-imdb

[5] Rolles, S. (2021). _Einführung in die Wahrscheinlichkeitstheorie und Statistik._ Vorlesungsskript TUM

[6] Bornemann, F. (2016). _Numerische lineare Algebra._ IV Kleinste Quadrate. https://doi.org/10.1007/978-3-658-24431-6

[7] Shapiro, S. S., & Wilk, M. B. (1965). _An Analysis of Variance Test for Normality (Complete Samples)._ Biometrika, 52(3/4), 591–611. https://doi.org/10.2307/2333709

[8] Kreutzmann, A. _Output einer linearen Regression in R._ https://wikis.fu-berlin.de/display/fustat/Output+einer+linearen+Regression+in+R

[9] Dreßler, G. _Netflix übertrumpft Amazon in Original-Produktionen._
https://www.digitalfernsehen.de/news/medien-news/maerkte/netflix-uebertrumpft-amazon-in-original-produktionen-554081/ (17. März 2020)